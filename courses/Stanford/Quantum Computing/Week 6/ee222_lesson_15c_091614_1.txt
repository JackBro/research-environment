The inverse operator is one that we use to work backwards. For an operator A, operating
on some arbitrary function f, then the inverse operator, if it exists, is the operator A
to the minus 1, such that f is equal to A to the minus 1, operating on the result of
A operating on f. So the idea is that the operator A does something to f, and the operator
A to the minus 1 undoes that.
Since this function f is arbitrary, we can therefore identify that A to the minus 1 times
A must equal the identity operator. If this expression is to work for any function f,
then this A to the minus 1 times A in here must be the identity operator. Since the operator
can be represented by a matrix, finding the inverse of an operator, finding this A to
the minus 1 reduces to finding the inverse of a matrix, which, of course, is a very well
known operation to perform on matrices.
As we discussed before, an operator takes an input vector and in general stretches it
and reorients it. The inverse operator does exactly the opposite, restoring the original
input vector. Just as in matrix theory, not all operators have inverses. An operator does
not have an inverse if it's what we could call a many to one operation.
That is, there is more than one input function that gives the same output function. Logically
then, there's no way to go backwards. We don't know which of the possible inputs to go back
to. Any linear operator that is a many to one operator like that will not have an inverse.
And the corresponding matrix representation of it will not have an inverse. A good example
of an operator that does not generally have an inverse is a projection operator. So a
projection operator might be like this. We have some specific function or vector f--
and here it is in ket form, and here it is in bra form. So we're taking the outer product
of these two. But in general, if we choose some specific value of f, this does not have
an inverse.
And the reason why is it projects all input vectors onto only one axis in this space,
the one corresponding to the specific vector f. So let's move on now to talk about unitary
operators. A unitary operator U, with a hat on it here, is one for which the inverse of
the unitary operator is equal to its Hermitian adjoint. The Hermitian adjoint of a matrix
is formed the same way as we did with a vector. We reflect on a minus 45 degree line-- that's
a line like this-- and take the complex conjugate.
So if this was our original matrix here and we take the Hermitian adjoint-- note the little
dagger here-- then what we've done is reflected about this diagonal line here, in this case,
a diagonal of the matrix, and taken the complex conjugates. So what was u21 down in here becomes
u21 star, the complex conjugate over here, and so on. From this rather abstract definition
of a unitary operator, it's not really at all clear why we would care about such an
operator, nor what it is really useful for.
In fact, unitary operators are very useful. And we will run through their properties here.
In particular, and this is not at all obvious from the definition, the key attribute of
a unitary operator is that it does not change the length of a vector. This is the unit part
in the word "unitary." So for example, if a unitary operator operates on a normalized
function, the result will also be normalized.
So quantum mechanical linear operators that change the state of the quantum mechanical
system from one state to another are generally unitary, because the state will presumably
still be normalized. For example, a particle such as an electron still has to be somewhere
after the state change, presumably. So normalization has to be retained.
Another major use of unitary operators is to change the representation of a vector,
that is, to change the coordinate system used to write down the vector. As we change the
coordinate system, we don't want to be changing the vector itself. So among other things,
we will not be changing its length. So let's take our first look at the mathematics of
unitary operators.
The key point then about unitary operators that gives them their name is that they conserve
length. Note first that it can be shown generally that for two matrices A and B that can be
multiplied, then the Hermitian adjoint of the product A times B of the two matrices
is the product of the Hermitian adjoints but flipped around. And this is easy to prove
if you use the summation notation for matrix or vector multiplication. We won't go through
the proof here, but it's quite straightforward.
So just to restate, that is, the Hermitian adjoint of the product is the flipped around
product of the Hermitian adjoints. And explicitly for matrix vector multiplication, because
vectors are the special cases algebraically of matrices, then if we take the Hermitian
adjoint of A operating on this ket vector here, then the result of that will be the
bra vector, which is the Hermitian adjoint of the ket vector, times the Hermitian adjoint
of the operator A.
Now, consider the unitary operator, U, and these two vectors here. So we're going to
call this one f old and g old. And we're going to see just where this important property
of conservation of length for unitary operators comes from. We're going to form two new vectors
by operating with this operator U. So let's form a new vector, f new that is the result
of operating with U on this old vector, f old. And similarly, for g here, we'll generate
a new g new from our old g by operating with the unitary operator U.
So let's just look at what the Hermitian adjoint of this g new ket vector is. It becomes this
bra vector. And as we said, when we take the Hermitian adjoint of the product of two things,
we'd have to take the flipped around product of the Hermitian adjoints. So we have the
bra vector for g old and the Hermitian adjoint of U.
So let's form this inner product between g new and f new. Well, we have our expression
for f new here. We have our expression for the bra vector version of g new here. Hence
we multiply the two of them together. But because this operator U is unitary, then this
product, the Hermitian adjoint times U, will be the same as the inverse of U times U.
And, of course, the inverse of U times U is just the identity operator. And that does
nothing at all. So therefore, what we've proved is that this unitary operation here acting
on these two vectors has done nothing to the inner product between the two vectors. So
our new vectors have the same inner product as the old ones did. So specifically then,
the unitary operation does not change the inner product.
And in particular, therefore, it doesn't change the inner product of a vector with itself,
because these g's and f's were arbitrary. So we can actually make them the same if we
want to. So what we proved is that this unitary operation does not change the inner product
of a vector with itself. And that means it does not change the length of a vector. So
a unitary operator is one that does not change the length of a vector.